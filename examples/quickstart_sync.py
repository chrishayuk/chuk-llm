#!/usr/bin/env python3
"""
ChukLLM QuickStart Demo - Basic Usage
=====================================

This demo shows the simplest ways to get started with ChukLLM.
Perfect for beginners and quick prototypes!
"""

# Basic imports - everything you need from one place
from chuk_llm import ask_sync, quick_question, configure

def demo_basic_usage():
    """Demonstrate the absolute basics."""
    print("üöÄ ChukLLM Basic Usage Demo")
    print("=" * 40)
    
    # 1. Simplest possible usage
    print("\n1Ô∏è‚É£ Ultra-simple one-liner:")
    answer = quick_question("What is 2 + 2?")
    print(f"   Q: What is 2 + 2?")
    print(f"   A: {answer}")
    
    # 2. Basic ask function
    print("\n2Ô∏è‚É£ Basic ask function:")
    response = ask_sync("Tell me a dad joke")
    print(f"   Q: Tell me a dad joke")
    print(f"   A: {response}")
    
    # 3. Configuration
    print("\n3Ô∏è‚É£ Configuration:")
    configure(temperature=0.9)  # Make responses more creative
    creative_response = ask_sync("Write a creative opening line for a story")
    print(f"   Q: Write a creative opening line for a story")
    print(f"   A: {creative_response}")
    
    print("\n‚úÖ Basic demo complete!")

def demo_provider_selection():
    """Show how to use different providers."""
    print("\nüîÑ Provider Selection Demo")
    print("=" * 40)
    
    question = "What's the capital of Japan?"
    
    # Try different providers
    providers_to_test = ["openai", "anthropic"]
    
    for provider in providers_to_test:
        try:
            response = ask_sync(question, provider=provider)
            print(f"\nüîπ {provider.title()}:")
            print(f"   {response[:100]}...")
        except Exception as e:
            print(f"\n‚ùå {provider.title()}: {str(e)[:50]}...")
    
    print("\n‚úÖ Provider selection demo complete!")

def demo_model_selection():
    """Show how to specify models explicitly."""
    print("\nüéØ Model Selection Demo")
    print("=" * 40)
    
    question = "Explain quantum computing in one sentence."
    
    # Test different models
    model_tests = [
        ("openai", "gpt-4o-mini"),
        ("anthropic", "claude-3-sonnet-20240229"),
    ]
    
    for provider, model in model_tests:
        try:
            response = ask_sync(question, provider=provider, model=model)
            print(f"\nüîπ {provider} ({model}):")
            print(f"   {response}")
        except Exception as e:
            print(f"\n‚ùå {provider} ({model}): {str(e)[:50]}...")
    
    print("\n‚úÖ Model selection demo complete!")

def demo_configuration_options():
    """Show various configuration options."""
    print("\n‚öôÔ∏è Configuration Options Demo")
    print("=" * 40)
    
    question = "Write three words about the weather"
    
    # Test different temperatures
    temperatures = [0.1, 0.5, 0.9]
    
    for temp in temperatures:
        response = ask_sync(question, temperature=temp, max_tokens=20)
        print(f"\nüå°Ô∏è Temperature {temp}:")
        print(f"   {response}")
    
    print("\n‚úÖ Configuration demo complete!")

if __name__ == "__main__":
    print("üéØ ChukLLM QuickStart - Basic Usage")
    print("This demo shows the fundamentals of ChukLLM")
    print("Set OPENAI_API_KEY and/or ANTHROPIC_API_KEY environment variables")
    print()
    
    try:
        demo_basic_usage()
        demo_provider_selection() 
        demo_model_selection()
        demo_configuration_options()
        
        print("\nüéâ All demos completed successfully!")
        print("\nüí° Next steps:")
        print("   ‚Ä¢ Try the advanced demo: python advanced_demo.py")
        print("   ‚Ä¢ Try the conversation demo: python conversation_demo.py") 
        print("   ‚Ä¢ Explore provider-specific functions: python provider_demo.py")
        
    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")
        print("\nüí° Make sure you have API keys configured:")
        print("   export OPENAI_API_KEY='your-key-here'")
        print("   export ANTHROPIC_API_KEY='your-key-here'")