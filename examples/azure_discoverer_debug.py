#!/usr/bin/env python3
"""
Debug version of Azure OpenAI discoverer to see exactly what URLs are being called
"""

import asyncio
import os
from pathlib import Path

import httpx

# Load environment variables
try:
    from dotenv import load_dotenv

    env_file = Path(".env")
    if env_file.exists():
        load_dotenv(env_file)
except ImportError:
    pass


class DebugAzureDiscoverer:
    """Debug version of Azure OpenAI discoverer"""

    def __init__(self):
        self.azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        self.api_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.api_version = "2024-02-01"

    async def debug_discover_models(self):
        """Debug the model discovery process step by step"""

        print("ğŸ› Debug Azure OpenAI Model Discovery")
        print("=" * 45)

        if not self.azure_endpoint or not self.api_key:
            print("âŒ Missing credentials")
            return

        print(f"ğŸ”— Endpoint: {self.azure_endpoint}")
        print(f"ğŸ”‘ API Key: {'*' * (len(self.api_key) - 8)}{self.api_key[-8:]}")
        print(f"ğŸ“… API Version: {self.api_version}")

        # Test the exact URL that should be called
        url = f"{self.azure_endpoint}/openai/models"
        params = {"api-version": self.api_version}
        headers = {"api-key": self.api_key}

        print(f"\nğŸ¯ Testing URL: {url}")
        print(f"ğŸ“‹ Params: {params}")
        print("ğŸ” Headers: api-key=***")

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                print("\nğŸ“¡ Making GET request...")
                response = await client.get(url, headers=headers, params=params)

                print(f"ğŸ“Š Response Status: {response.status_code}")
                print(f"ğŸ“‹ Response Headers: {dict(response.headers)}")

                if response.status_code == 200:
                    print("âœ… SUCCESS!")
                    try:
                        data = response.json()
                        models = data.get("data", [])
                        print(f"ğŸ“š Found {len(models)} models:")
                        for i, model in enumerate(models[:5]):  # Show first 5
                            model_id = model.get("id", "unknown")
                            owned_by = model.get("owned_by", "unknown")
                            print(f"   {i + 1}. {model_id} (owned by: {owned_by})")
                        if len(models) > 5:
                            print(f"   ... and {len(models) - 5} more models")
                    except Exception as e:
                        print(f"âŒ Failed to parse JSON: {e}")
                        print(f"ğŸ“„ Raw response: {response.text[:200]}...")

                elif response.status_code == 404:
                    print("âŒ 404 NOT FOUND")
                    print("ğŸ’¡ This means the /openai/models endpoint doesn't exist")
                    print("ğŸ” Let's try alternative endpoints...")

                    # Try alternative endpoints
                    alternatives = [
                        f"{self.azure_endpoint}/models",
                        f"{self.azure_endpoint.replace('/openai', '')}/openai/models",
                        f"{self.azure_endpoint.replace('/openai', '')}/models",
                    ]

                    for alt_url in alternatives:
                        print(f"\nğŸ”„ Trying: {alt_url}")
                        try:
                            alt_response = await client.get(
                                alt_url, headers=headers, params=params
                            )
                            print(f"   Status: {alt_response.status_code}")
                            if alt_response.status_code == 200:
                                print("   âœ… WORKS!")
                                try:
                                    alt_data = alt_response.json()
                                    alt_models = alt_data.get("data", [])
                                    print(f"   ğŸ“š Found {len(alt_models)} models")
                                except:
                                    print(
                                        f"   ğŸ“„ Response length: {len(alt_response.text)}"
                                    )
                            else:
                                print(f"   âŒ {alt_response.status_code}")
                        except Exception as e:
                            print(f"   ğŸ’¥ Error: {str(e)[:50]}...")

                elif response.status_code == 401:
                    print("âŒ 401 UNAUTHORIZED - Check API key")
                elif response.status_code == 403:
                    print("âŒ 403 FORBIDDEN - Check permissions")
                else:
                    print(f"âŒ Unexpected status: {response.status_code}")
                    print(f"ğŸ“„ Response: {response.text[:200]}...")

        except Exception as e:
            print(f"ğŸ’¥ Request failed: {e}")

    async def debug_test_chat_completion(self):
        """Test if chat completions work to verify endpoint format"""

        print("\nğŸ’¬ Testing Chat Completions (to verify endpoint format)")
        print("=" * 55)

        # Try common deployment names
        deployment_names = ["gpt-4o-mini", "gpt-4o", "gpt-4", "gpt-35-turbo"]

        for deployment in deployment_names:
            url = f"{self.azure_endpoint}/openai/deployments/{deployment}/chat/completions"
            params = {"api-version": self.api_version}
            headers = {"api-key": self.api_key, "Content-Type": "application/json"}

            payload = {"messages": [{"role": "user", "content": "Hi"}], "max_tokens": 5}

            print(f"\nğŸ¯ Testing deployment: {deployment}")
            print(f"ğŸ“¡ URL: {url}")

            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.post(
                        url, headers=headers, params=params, json=payload
                    )

                    if response.status_code == 200:
                        print(f"   âœ… WORKS - {deployment} is deployed!")
                        return deployment  # Found a working deployment
                    elif response.status_code == 404:
                        print(f"   âŒ 404 - {deployment} not deployed")
                    else:
                        print(f"   â“ {response.status_code} - {deployment}")

            except Exception as e:
                print(f"   ğŸ’¥ Error: {str(e)[:30]}...")

        print("\nâŒ No working deployments found")
        return None


async def main():
    """Main debug function"""
    debugger = DebugAzureDiscoverer()

    # Test model discovery
    await debugger.debug_discover_models()

    # Test chat completions
    working_deployment = await debugger.debug_test_chat_completion()

    print("\nğŸ“‹ Debug Summary:")
    print("   â€¢ Azure endpoint format appears to be correct")
    print(
        "   â€¢ The /openai/models endpoint may not exist in your Azure OpenAI instance"
    )
    print(f"   â€¢ Chat completions work: {'Yes' if working_deployment else 'No'}")
    if working_deployment:
        print(f"   â€¢ Working deployment found: {working_deployment}")

    print("\nğŸ’¡ Possible explanations:")
    print("   1. Azure OpenAI may not support the /openai/models listing endpoint")
    print("   2. Your Azure OpenAI resource may be configured differently")
    print("   3. The API version may not support model listing")
    print("   4. This might be an older Azure OpenAI instance")


if __name__ == "__main__":
    asyncio.run(main())
